"use client";

import { useState, useRef, useCallback } from "react";

interface Message {
  id: string;
  role: "user" | "assistant";
  content: string;
  timestamp: Date;
}

interface UseRealtimeOptions {
  scenario: string;
  level: "beginner" | "intermediate" | "advanced";
  onMessage?: (message: Message) => void;
  onError?: (error: string) => void;
}

export function useRealtime(options: UseRealtimeOptions) {
  const { scenario, level, onMessage, onError } = options;

  const [isConnected, setIsConnected] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [isAiSpeaking, setIsAiSpeaking] = useState(false);
  const [messages, setMessages] = useState<Message[]>([]);
  const [hasMicrophone, setHasMicrophone] = useState(true);
  const [connectionError, setConnectionError] = useState<string | null>(null);
  const [debugLogs, setDebugLogs] = useState<string[]>([]);

  const addLog = (message: string) => {
    console.log(message);
    setDebugLogs(prev => [...prev.slice(-20), `${new Date().toLocaleTimeString()}: ${message}`]);
  };

  const peerConnection = useRef<RTCPeerConnection | null>(null);
  const dataChannel = useRef<RTCDataChannel | null>(null);
  const audioElement = useRef<HTMLAudioElement | null>(null);
  const mediaStream = useRef<MediaStream | null>(null);

  const levelInstructions = {
    beginner: "Speak slowly and use very simple English. Use short sentences with basic vocabulary. If the student makes mistakes, gently correct them.",
    intermediate: "Use everyday conversational English. Speak at a moderate pace. Introduce some common idioms and expressions.",
    advanced: "Speak naturally at normal pace. Use varied vocabulary and complex sentences. Challenge the student with nuanced expressions.",
  };

  const connect = useCallback(async () => {
    setConnectionError(null);
    setDebugLogs([]);
    addLog("=== ì—°ê²° ì‹œìž‘ ===");

    try {
      // 1. ì„¸ì…˜ í† í° ê°€ì ¸ì˜¤ê¸°
      addLog("1ë‹¨ê³„: ì„¸ì…˜ í† í° ìš”ì²­ ì¤‘...");
      const tokenResponse = await fetch("/api/realtime/session");
      addLog(`í† í° ì‘ë‹µ: ${tokenResponse.status}`);

      if (!tokenResponse.ok) {
        const errorText = await tokenResponse.text();
        addLog(`í† í° ì—ëŸ¬: ${errorText}`);
        throw new Error("ì„¸ì…˜ í† í°ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤");
      }

      const sessionData = await tokenResponse.json();
      addLog(`ì„¸ì…˜ ë°ì´í„°: ${sessionData.id ? "ì„±ê³µ" : "ì‹¤íŒ¨"}`);

      if (!sessionData.client_secret) {
        addLog("client_secret ì—†ìŒ!");
        throw new Error("ì„¸ì…˜ í† í°ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤");
      }

      const { client_secret } = sessionData;

      // 2. WebRTC ì—°ê²° ì„¤ì •
      const pc = new RTCPeerConnection({
        iceServers: [{ urls: "stun:stun.l.google.com:19302" }],
      });
      peerConnection.current = pc;

      // ICE ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§
      pc.oniceconnectionstatechange = () => {
        addLog(`ICE ìƒíƒœ: ${pc.iceConnectionState}`);
        if (pc.iceConnectionState === "failed" || pc.iceConnectionState === "disconnected") {
          onError?.("ì—°ê²°ì´ ëŠì–´ì¡ŒìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
        }
      };

      pc.onconnectionstatechange = () => {
        addLog(`ì—°ê²° ìƒíƒœ: ${pc.connectionState}`);
      };

      pc.onicegatheringstatechange = () => {
        addLog(`ICE ìˆ˜ì§‘: ${pc.iceGatheringState}`);
      };

      // 3. ì˜¤ë””ì˜¤ ì¶œë ¥ ì„¤ì • (ëª¨ë°”ì¼ ë¸Œë¼ìš°ì € í˜¸í™˜)
      const audio = document.createElement("audio");
      audio.autoplay = true;
      audio.muted = false;
      audio.volume = 1.0;
      audio.setAttribute("playsinline", "true");
      audio.setAttribute("webkit-playsinline", "true");
      audio.style.cssText = "position:fixed;top:-1000px;left:-1000px;";
      document.body.appendChild(audio);
      audioElement.current = audio;

      // ì˜¤ë””ì˜¤ ìˆ˜ì‹ ìš© íŠ¸ëžœì‹œë²„ ì¶”ê°€
      pc.addTransceiver("audio", { direction: "recvonly" });

      pc.ontrack = (event) => {
        addLog("ðŸ”Š ì˜¤ë””ì˜¤ íŠ¸ëž™ ìˆ˜ì‹ !");
        addLog(`íŠ¸ëž™ ì¢…ë¥˜: ${event.track.kind}, ìƒíƒœ: ${event.track.readyState}`);

        const stream = event.streams[0];
        audio.srcObject = stream;

        // ëª¨ë°”ì¼ì—ì„œ ì˜¤ë””ì˜¤ ìž¬ìƒ ì‹œìž‘
        const playAudio = () => {
          audio.play().then(() => {
            addLog("âœ… ì˜¤ë””ì˜¤ ìž¬ìƒ ì„±ê³µ!");
          }).catch((e) => {
            addLog(`âš ï¸ ì˜¤ë””ì˜¤ ìž¬ìƒ ì‹¤íŒ¨: ${e.message}`);
            // ì‚¬ìš©ìž ì¸í„°ëž™ì…˜ ëŒ€ê¸°
            document.addEventListener("click", () => {
              audio.play().then(() => addLog("âœ… í´ë¦­ í›„ ì˜¤ë””ì˜¤ ìž¬ìƒ ì„±ê³µ"));
            }, { once: true });
          });
        };

        playAudio();
        setIsAiSpeaking(true);
      };

      // 4. ë§ˆì´í¬ ìž…ë ¥ ì„¤ì •
      addLog("4ë‹¨ê³„: ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­...");
      addLog(`mediaDevices ì§€ì›: ${!!navigator.mediaDevices}`);

      try {
        // ë¨¼ì € ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ìž¥ì¹˜ í™•ì¸
        const devices = await navigator.mediaDevices.enumerateDevices();
        const audioInputs = devices.filter(d => d.kind === "audioinput");
        addLog(`ì˜¤ë””ì˜¤ ìž…ë ¥ ìž¥ì¹˜: ${audioInputs.length}ê°œ`);

        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaStream.current = stream;
        stream.getTracks().forEach((track) => {
          addLog(`ë§ˆì´í¬ íŠ¸ëž™: ${track.label || "ì´ë¦„ì—†ìŒ"}`);
          pc.addTrack(track, stream);
        });
        addLog("ë§ˆì´í¬ ì—°ê²° ì„±ê³µ!");
        setHasMicrophone(true);
        setIsRecording(true); // ë§ˆì´í¬ ê¸°ë³¸ í™œì„±í™”
      } catch (micError: unknown) {
        const errorMessage = micError instanceof Error ? micError.message : String(micError);
        const errorName = micError instanceof Error ? micError.name : "Unknown";
        addLog(`ë§ˆì´í¬ ì—ëŸ¬: ${errorName} - ${errorMessage}`);
        setHasMicrophone(false);

        if (errorName === "NotFoundError") {
          setConnectionError("ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìžˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.");
        } else if (errorName === "NotAllowedError") {
          setConnectionError("ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ë¥¼ í—ˆìš©í•´ì£¼ì„¸ìš”.");
        } else {
          setConnectionError(`ë§ˆì´í¬ ì˜¤ë¥˜: ${errorMessage}`);
        }
        throw micError;
      }

      // 5. ë°ì´í„° ì±„ë„ ì„¤ì • (í…ìŠ¤íŠ¸ í†µì‹ ìš©)
      addLog("5ë‹¨ê³„: ë°ì´í„° ì±„ë„ ìƒì„±...");
      const dc = pc.createDataChannel("oai-events");
      dataChannel.current = dc;

      dc.onopen = () => {
        addLog("âœ… ë°ì´í„° ì±„ë„ ì—´ë¦¼!");
        // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì „ì†¡
        const systemPrompt = {
          type: "session.update",
          session: {
            modalities: ["text", "audio"],
            voice: "alloy",
            instructions: `You are a friendly English teacher helping a Korean family learn English through role-play scenarios.

Current scenario: "${scenario}"
Student level: ${level}

${levelInstructions[level]}

Important guidelines:
- Always stay in character for the scenario
- After each student response, briefly acknowledge what they said
- If they speak Korean, gently encourage them to try in English
- Keep responses concise (1-2 sentences)
- Be encouraging and supportive

Start by greeting the student and setting up the scenario context in English.`,
            input_audio_transcription: { model: "whisper-1" },
            turn_detection: {
              type: "server_vad",
              threshold: 0.5,
              prefix_padding_ms: 300,
              silence_duration_ms: 500,
            },
          },
        };
        dc.send(JSON.stringify(systemPrompt));
        addLog("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì „ì†¡ ì™„ë£Œ");

        // ì‘ë‹µ ìƒì„± ìš”ì²­
        dc.send(JSON.stringify({ type: "response.create" }));
        addLog("ì‘ë‹µ ìƒì„± ìš”ì²­ ì „ì†¡");
      };

      dc.onerror = (error) => {
        addLog(`âŒ ë°ì´í„° ì±„ë„ ì—ëŸ¬: ${error}`);
      };

      dc.onclose = () => {
        addLog("ë°ì´í„° ì±„ë„ ë‹«íž˜");
      };

      dc.onmessage = (event) => {
        const data = JSON.parse(event.data);
        addLog(`ðŸ“¨ ìˆ˜ì‹ : ${data.type}`);

        switch (data.type) {
          case "response.audio_transcript.done":
            // AI ì‘ë‹µ í…ìŠ¤íŠ¸
            const aiMessage: Message = {
              id: crypto.randomUUID(),
              role: "assistant",
              content: data.transcript,
              timestamp: new Date(),
            };
            setMessages((prev) => [...prev, aiMessage]);
            onMessage?.(aiMessage);
            break;

          case "conversation.item.input_audio_transcription.completed":
            // ì‚¬ìš©ìž ìŒì„± í…ìŠ¤íŠ¸
            const userMessage: Message = {
              id: crypto.randomUUID(),
              role: "user",
              content: data.transcript,
              timestamp: new Date(),
            };
            setMessages((prev) => [...prev, userMessage]);
            onMessage?.(userMessage);
            break;

          case "conversation.item.input_audio_transcription.failed":
            addLog(`âŒ ìŒì„±ì¸ì‹ ì‹¤íŒ¨: ${JSON.stringify(data)}`);
            break;

          case "response.audio.delta":
            // ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹  ì¤‘
            break;

          case "response.audio.done":
            setIsAiSpeaking(false);
            break;

          case "response.output_item.added":
            addLog("ðŸŽ¤ AI ì‘ë‹µ ì‹œìž‘");
            break;

          case "error":
            addLog(`âŒ API ì—ëŸ¬: ${data.error?.message || JSON.stringify(data)}`);
            onError?.(data.error?.message || "Unknown error");
            break;
        }
      };

      // 6. SDP Offer ìƒì„± ë° ì „ì†¡
      addLog("6ë‹¨ê³„: SDP ì˜¤í¼ ìƒì„±...");
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);
      addLog("SDP ì˜¤í¼ ìƒì„± ì™„ë£Œ");

      addLog("7ë‹¨ê³„: OpenAIì— SDP ì „ì†¡...");
      const sdpResponse = await fetch(
        "https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17",
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${client_secret.value}`,
            "Content-Type": "application/sdp",
          },
          body: offer.sdp,
        }
      );

      addLog(`SDP ì‘ë‹µ: ${sdpResponse.status}`);
      if (!sdpResponse.ok) {
        const errorText = await sdpResponse.text();
        addLog(`SDP ì—ëŸ¬: ${errorText}`);
        throw new Error("WebRTC ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤");
      }

      const answerSdp = await sdpResponse.text();
      addLog("8ë‹¨ê³„: ì›ê²© ì„¤ëª… ì„¤ì •...");
      await pc.setRemoteDescription({ type: "answer", sdp: answerSdp });

      addLog("=== ì—°ê²° ì„±ê³µ! ===");
      setIsConnected(true);
    } catch (error) {
      console.error("Connection error:", error);
      onError?.(error instanceof Error ? error.message : "Connection failed");
    }
  }, [scenario, level, onMessage, onError]);

  const disconnect = useCallback(() => {
    // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì •ì§€
    mediaStream.current?.getTracks().forEach((track) => track.stop());
    mediaStream.current = null;

    // ì˜¤ë””ì˜¤ ì •ì§€ ë° DOMì—ì„œ ì œê±°
    if (audioElement.current) {
      audioElement.current.pause();
      audioElement.current.srcObject = null;
      audioElement.current.remove();
      audioElement.current = null;
    }

    // WebRTC ì—°ê²° ì¢…ë£Œ
    dataChannel.current?.close();
    peerConnection.current?.close();
    dataChannel.current = null;
    peerConnection.current = null;

    setIsConnected(false);
    setIsRecording(false);
    setIsAiSpeaking(false);
  }, []);

  const toggleRecording = useCallback(() => {
    if (!mediaStream.current) return;

    const audioTrack = mediaStream.current.getAudioTracks()[0];
    if (audioTrack) {
      audioTrack.enabled = !audioTrack.enabled;
      setIsRecording(audioTrack.enabled);
    }
  }, []);

  const sendTextMessage = useCallback((text: string) => {
    if (!dataChannel.current || dataChannel.current.readyState !== "open") {
      return;
    }

    // í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡
    const event = {
      type: "conversation.item.create",
      item: {
        type: "message",
        role: "user",
        content: [{ type: "input_text", text }],
      },
    };
    dataChannel.current.send(JSON.stringify(event));

    // ì‘ë‹µ ìš”ì²­
    dataChannel.current.send(JSON.stringify({ type: "response.create" }));

    // ë¡œì»¬ ë©”ì‹œì§€ ì¶”ê°€
    const userMessage: Message = {
      id: crypto.randomUUID(),
      role: "user",
      content: text,
      timestamp: new Date(),
    };
    setMessages((prev) => [...prev, userMessage]);
    onMessage?.(userMessage);
  }, [onMessage]);

  return {
    isConnected,
    isRecording,
    isAiSpeaking,
    messages,
    hasMicrophone,
    connectionError,
    debugLogs,
    connect,
    disconnect,
    toggleRecording,
    sendTextMessage,
  };
}
