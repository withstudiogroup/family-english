"use client";

import { useState, useRef, useCallback } from "react";

interface Message {
  id: string;
  role: "user" | "assistant";
  content: string;
  timestamp: Date;
}

interface UseRealtimeOptions {
  scenario: string;
  level: "beginner" | "intermediate" | "advanced";
  onMessage?: (message: Message) => void;
  onError?: (error: string) => void;
}

export function useRealtime(options: UseRealtimeOptions) {
  const { scenario, level, onMessage, onError } = options;

  const [isConnected, setIsConnected] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [isAiSpeaking, setIsAiSpeaking] = useState(false);
  const [messages, setMessages] = useState<Message[]>([]);
  const [hasMicrophone, setHasMicrophone] = useState(true);
  const [connectionError, setConnectionError] = useState<string | null>(null);
  const [debugLogs, setDebugLogs] = useState<string[]>([]);

  const addLog = (message: string) => {
    console.log(message);
    setDebugLogs(prev => [...prev.slice(-20), `${new Date().toLocaleTimeString()}: ${message}`]);
  };

  const peerConnection = useRef<RTCPeerConnection | null>(null);
  const dataChannel = useRef<RTCDataChannel | null>(null);
  const audioElement = useRef<HTMLAudioElement | null>(null);
  const mediaStream = useRef<MediaStream | null>(null);

  const levelInstructions = {
    beginner: `You are teaching a Korean elementary school student (grades 1-3) who is JUST STARTING to learn English.

CRITICAL RULES for Beginner Level:
- Use ONLY the most basic words (hello, goodbye, yes, no, colors, numbers 1-10, family words)
- Keep ALL sentences to 3-5 words MAXIMUM. Example: "Hello! What is your name?"
- Speak EXTREMELY slowly with clear pauses between words
- REPEAT important words 2-3 times: "Apple. AP-PLE. Apple."
- Use LOTS of encouragement: "Great!", "Good job!", "Perfect!"
- If student doesn't understand, use SIMPLER words, not more words
- NEVER use complex grammar (no perfect tenses, no conditionals, no passive voice)
- NEVER use idioms, slang, or phrasal verbs
- Ask only ONE simple question at a time
- Wait patiently for responses

Example good interaction:
Teacher: "Hello! What... is... your... name?"
Student: "Tom"
Teacher: "Hi Tom! Nice... to... meet... you!"`,

    intermediate: `You are teaching a Korean elementary student (grades 4-6) with basic English knowledge.

Rules for Intermediate Level:
- Use everyday conversational English
- Keep sentences to 8-12 words
- Speak at a moderate, clear pace
- Introduce common expressions naturally
- Ask follow-up questions to extend conversation
- If student makes grammar mistakes, gently model the correct form
- Example: Student says "I go school yesterday" â†’ You say "Oh, you WENT to school yesterday! What did you do?"
- Be encouraging but challenge them a bit`,

    advanced: `You are teaching a Korean middle school student who wants to speak like a native.

Rules for Advanced Level:
- Use natural, native-like expressions
- Speak at normal conversational speed
- Use varied vocabulary and complex sentences
- Discuss abstract topics and opinions
- Point out nuances and suggest more natural expressions
- Challenge with "Why?" and "How do you feel about that?"
- Treat them as a peer refining their English`,
  };

  const connect = useCallback(async () => {
    setConnectionError(null);
    setDebugLogs([]);
    addLog("=== ì—°ê²° ì‹œìž‘ ===");

    try {
      // 1. ì„¸ì…˜ í† í° ê°€ì ¸ì˜¤ê¸°
      addLog("1ë‹¨ê³„: ì„¸ì…˜ í† í° ìš”ì²­ ì¤‘...");
      const tokenResponse = await fetch("/api/realtime/session");
      addLog(`í† í° ì‘ë‹µ: ${tokenResponse.status}`);

      if (!tokenResponse.ok) {
        const errorText = await tokenResponse.text();
        addLog(`í† í° ì—ëŸ¬: ${errorText}`);
        throw new Error("ì„¸ì…˜ í† í°ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤");
      }

      const sessionData = await tokenResponse.json();
      addLog(`ì„¸ì…˜ ë°ì´í„°: ${sessionData.id ? "ì„±ê³µ" : "ì‹¤íŒ¨"}`);

      if (!sessionData.client_secret) {
        addLog("client_secret ì—†ìŒ!");
        throw new Error("ì„¸ì…˜ í† í°ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤");
      }

      const { client_secret } = sessionData;

      // 2. WebRTC ì—°ê²° ì„¤ì •
      const pc = new RTCPeerConnection({
        iceServers: [{ urls: "stun:stun.l.google.com:19302" }],
      });
      peerConnection.current = pc;

      // ICE ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§
      pc.oniceconnectionstatechange = () => {
        addLog(`ICE ìƒíƒœ: ${pc.iceConnectionState}`);
        if (pc.iceConnectionState === "failed" || pc.iceConnectionState === "disconnected") {
          onError?.("ì—°ê²°ì´ ëŠì–´ì¡ŒìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
        }
      };

      pc.onconnectionstatechange = () => {
        addLog(`ì—°ê²° ìƒíƒœ: ${pc.connectionState}`);
      };

      pc.onicegatheringstatechange = () => {
        addLog(`ICE ìˆ˜ì§‘: ${pc.iceGatheringState}`);
      };

      // 3. ì˜¤ë””ì˜¤ ì¶œë ¥ ì„¤ì • (ëª¨ë°”ì¼ ë¸Œë¼ìš°ì € í˜¸í™˜)
      const audio = document.createElement("audio");
      audio.autoplay = true;
      audio.muted = false;
      audio.volume = 1.0;
      audio.setAttribute("playsinline", "true");
      audio.setAttribute("webkit-playsinline", "true");
      audio.style.cssText = "position:fixed;top:-1000px;left:-1000px;";
      document.body.appendChild(audio);
      audioElement.current = audio;

      // ì˜¤ë””ì˜¤ ìˆ˜ì‹ ìš© íŠ¸ëžœì‹œë²„ ì¶”ê°€
      pc.addTransceiver("audio", { direction: "recvonly" });

      pc.ontrack = (event) => {
        addLog("ðŸ”Š ì˜¤ë””ì˜¤ íŠ¸ëž™ ìˆ˜ì‹ !");
        addLog(`íŠ¸ëž™ ì¢…ë¥˜: ${event.track.kind}, ìƒíƒœ: ${event.track.readyState}`);

        const stream = event.streams[0];
        audio.srcObject = stream;

        // ëª¨ë°”ì¼ì—ì„œ ì˜¤ë””ì˜¤ ìž¬ìƒ ì‹œìž‘
        const playAudio = () => {
          audio.play().then(() => {
            addLog("âœ… ì˜¤ë””ì˜¤ ìž¬ìƒ ì„±ê³µ!");
          }).catch((e) => {
            addLog(`âš ï¸ ì˜¤ë””ì˜¤ ìž¬ìƒ ì‹¤íŒ¨: ${e.message}`);
            // ì‚¬ìš©ìž ì¸í„°ëž™ì…˜ ëŒ€ê¸°
            document.addEventListener("click", () => {
              audio.play().then(() => addLog("âœ… í´ë¦­ í›„ ì˜¤ë””ì˜¤ ìž¬ìƒ ì„±ê³µ"));
            }, { once: true });
          });
        };

        playAudio();
        setIsAiSpeaking(true);
      };

      // 4. ë§ˆì´í¬ ìž…ë ¥ ì„¤ì •
      addLog("4ë‹¨ê³„: ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­...");
      addLog(`mediaDevices ì§€ì›: ${!!navigator.mediaDevices}`);

      try {
        // ë¨¼ì € ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ìž¥ì¹˜ í™•ì¸
        const devices = await navigator.mediaDevices.enumerateDevices();
        const audioInputs = devices.filter(d => d.kind === "audioinput");
        addLog(`ì˜¤ë””ì˜¤ ìž…ë ¥ ìž¥ì¹˜: ${audioInputs.length}ê°œ`);

        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaStream.current = stream;
        stream.getTracks().forEach((track) => {
          addLog(`ë§ˆì´í¬ íŠ¸ëž™: ${track.label || "ì´ë¦„ì—†ìŒ"}`);
          pc.addTrack(track, stream);
        });
        addLog("ë§ˆì´í¬ ì—°ê²° ì„±ê³µ!");
        setHasMicrophone(true);
        setIsRecording(true); // ë§ˆì´í¬ ê¸°ë³¸ í™œì„±í™”
      } catch (micError: unknown) {
        const errorMessage = micError instanceof Error ? micError.message : String(micError);
        const errorName = micError instanceof Error ? micError.name : "Unknown";
        addLog(`ë§ˆì´í¬ ì—ëŸ¬: ${errorName} - ${errorMessage}`);
        setHasMicrophone(false);

        if (errorName === "NotFoundError") {
          setConnectionError("ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìžˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.");
        } else if (errorName === "NotAllowedError") {
          setConnectionError("ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ë¥¼ í—ˆìš©í•´ì£¼ì„¸ìš”.");
        } else {
          setConnectionError(`ë§ˆì´í¬ ì˜¤ë¥˜: ${errorMessage}`);
        }
        throw micError;
      }

      // 5. ë°ì´í„° ì±„ë„ ì„¤ì • (í…ìŠ¤íŠ¸ í†µì‹ ìš©)
      addLog("5ë‹¨ê³„: ë°ì´í„° ì±„ë„ ìƒì„±...");
      const dc = pc.createDataChannel("oai-events");
      dataChannel.current = dc;

      dc.onopen = () => {
        addLog("âœ… ë°ì´í„° ì±„ë„ ì—´ë¦¼!");
        // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì „ì†¡
        const systemPrompt = {
          type: "session.update",
          session: {
            modalities: ["text", "audio"],
            voice: "alloy",
            instructions: `You are a friendly, patient English teacher for Korean students.

=== ABSOLUTE RULES (NEVER BREAK THESE) ===
1. ALWAYS speak and respond ONLY in English. NEVER use Korean, Japanese, Chinese, or any other language.
2. Even if the student speaks in Korean or another language, YOU must ALWAYS respond in English only.
3. If you don't understand the student, say "Sorry, can you say that again?" in English.

=== CURRENT SESSION ===
Scenario: "${scenario}"
Student Level: ${level}

=== LEVEL-SPECIFIC INSTRUCTIONS ===
${levelInstructions[level]}

=== SCENARIO GUIDELINES ===
- Stay in character for the "${scenario}" scenario
- Keep your responses SHORT (1-2 sentences for beginner, 2-3 for others)
- Be encouraging and positive
- If student is stuck, offer a simple hint in English

=== START ===
Greet the student warmly in English and begin the scenario.`,
            input_audio_transcription: { model: "whisper-1" },
            turn_detection: {
              type: "server_vad",
              threshold: 0.5,
              prefix_padding_ms: 300,
              silence_duration_ms: 500,
            },
          },
        };
        dc.send(JSON.stringify(systemPrompt));
        addLog("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì „ì†¡ ì™„ë£Œ");

        // ì‘ë‹µ ìƒì„± ìš”ì²­
        dc.send(JSON.stringify({ type: "response.create" }));
        addLog("ì‘ë‹µ ìƒì„± ìš”ì²­ ì „ì†¡");
      };

      dc.onerror = (error) => {
        addLog(`âŒ ë°ì´í„° ì±„ë„ ì—ëŸ¬: ${error}`);
      };

      dc.onclose = () => {
        addLog("ë°ì´í„° ì±„ë„ ë‹«íž˜");
      };

      dc.onmessage = (event) => {
        const data = JSON.parse(event.data);
        addLog(`ðŸ“¨ ìˆ˜ì‹ : ${data.type}`);

        switch (data.type) {
          case "response.audio_transcript.done":
            // AI ì‘ë‹µ í…ìŠ¤íŠ¸
            const aiMessage: Message = {
              id: crypto.randomUUID(),
              role: "assistant",
              content: data.transcript,
              timestamp: new Date(),
            };
            setMessages((prev) => [...prev, aiMessage]);
            onMessage?.(aiMessage);
            break;

          case "conversation.item.input_audio_transcription.completed":
            // ì‚¬ìš©ìž ìŒì„± í…ìŠ¤íŠ¸
            const userMessage: Message = {
              id: crypto.randomUUID(),
              role: "user",
              content: data.transcript,
              timestamp: new Date(),
            };
            setMessages((prev) => [...prev, userMessage]);
            onMessage?.(userMessage);
            break;

          case "conversation.item.input_audio_transcription.failed":
            addLog(`âŒ ìŒì„±ì¸ì‹ ì‹¤íŒ¨: ${JSON.stringify(data)}`);
            break;

          case "response.audio.delta":
            // ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹  ì¤‘
            break;

          case "response.audio.done":
            setIsAiSpeaking(false);
            break;

          case "response.output_item.added":
            addLog("ðŸŽ¤ AI ì‘ë‹µ ì‹œìž‘");
            break;

          case "error":
            addLog(`âŒ API ì—ëŸ¬: ${data.error?.message || JSON.stringify(data)}`);
            onError?.(data.error?.message || "Unknown error");
            break;
        }
      };

      // 6. SDP Offer ìƒì„± ë° ì „ì†¡
      addLog("6ë‹¨ê³„: SDP ì˜¤í¼ ìƒì„±...");
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);
      addLog("SDP ì˜¤í¼ ìƒì„± ì™„ë£Œ");

      addLog("7ë‹¨ê³„: OpenAIì— SDP ì „ì†¡...");
      const sdpResponse = await fetch(
        "https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17",
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${client_secret.value}`,
            "Content-Type": "application/sdp",
          },
          body: offer.sdp,
        }
      );

      addLog(`SDP ì‘ë‹µ: ${sdpResponse.status}`);
      if (!sdpResponse.ok) {
        const errorText = await sdpResponse.text();
        addLog(`SDP ì—ëŸ¬: ${errorText}`);
        throw new Error("WebRTC ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤");
      }

      const answerSdp = await sdpResponse.text();
      addLog("8ë‹¨ê³„: ì›ê²© ì„¤ëª… ì„¤ì •...");
      await pc.setRemoteDescription({ type: "answer", sdp: answerSdp });

      addLog("=== ì—°ê²° ì„±ê³µ! ===");
      setIsConnected(true);
    } catch (error) {
      console.error("Connection error:", error);
      onError?.(error instanceof Error ? error.message : "Connection failed");
    }
  }, [scenario, level, onMessage, onError]);

  const disconnect = useCallback(() => {
    // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì •ì§€
    mediaStream.current?.getTracks().forEach((track) => track.stop());
    mediaStream.current = null;

    // ì˜¤ë””ì˜¤ ì •ì§€ ë° DOMì—ì„œ ì œê±°
    if (audioElement.current) {
      audioElement.current.pause();
      audioElement.current.srcObject = null;
      audioElement.current.remove();
      audioElement.current = null;
    }

    // WebRTC ì—°ê²° ì¢…ë£Œ
    dataChannel.current?.close();
    peerConnection.current?.close();
    dataChannel.current = null;
    peerConnection.current = null;

    setIsConnected(false);
    setIsRecording(false);
    setIsAiSpeaking(false);
  }, []);

  const toggleRecording = useCallback(() => {
    if (!mediaStream.current) return;

    const audioTrack = mediaStream.current.getAudioTracks()[0];
    if (audioTrack) {
      audioTrack.enabled = !audioTrack.enabled;
      setIsRecording(audioTrack.enabled);
    }
  }, []);

  const sendTextMessage = useCallback((text: string) => {
    if (!dataChannel.current || dataChannel.current.readyState !== "open") {
      return;
    }

    // í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡
    const event = {
      type: "conversation.item.create",
      item: {
        type: "message",
        role: "user",
        content: [{ type: "input_text", text }],
      },
    };
    dataChannel.current.send(JSON.stringify(event));

    // ì‘ë‹µ ìš”ì²­
    dataChannel.current.send(JSON.stringify({ type: "response.create" }));

    // ë¡œì»¬ ë©”ì‹œì§€ ì¶”ê°€
    const userMessage: Message = {
      id: crypto.randomUUID(),
      role: "user",
      content: text,
      timestamp: new Date(),
    };
    setMessages((prev) => [...prev, userMessage]);
    onMessage?.(userMessage);
  }, [onMessage]);

  return {
    isConnected,
    isRecording,
    isAiSpeaking,
    messages,
    hasMicrophone,
    connectionError,
    debugLogs,
    connect,
    disconnect,
    toggleRecording,
    sendTextMessage,
  };
}
